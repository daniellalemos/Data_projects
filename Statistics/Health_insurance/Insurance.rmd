---
title: "Health Insurance"
output:
  pdf_document:
    toc: yes
---

```{r setup, cache = FALSE, echo = FALSE}
options(width = 107, digits = 4) 
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE, warning = FALSE, message = FALSE, error = FALSE) 
```

Introduction
The data we used are related to health insurance that were simulated based on demographic statistics collected by the United States Census Bureau (USCB), available at "https://www.kaggle.com/mirichoi0218/insurance".

The variables in this dataset correspond to parameters that influence the value of medical expenses charged by health insurance. For the implementation of linear regression, we selected the charges as the dependent variable since it depends on all the others. Therefore, with this work, we aim to assess the influence of age, gender, BMI, number of children, smoking status, and region of residence of each insured individual on the individual medical expenses charged by health insurance.

Variables
Age: age of the beneficiary/insured;

Gender: gender of the insured (male/female);

BMI: body mass index that provides insight into the body, indicating weights that are relatively high or low compared to height. Ideally, the objective body weight index will be from 18.5 to 24.9 kg/m^2^, for which the ratio of height to weight is used;

Children: number of children covered by health insurance (number of dependents);

Smoker: indicator of whether they smoke (yes/no);

Region: region of the US where the beneficiary lives (northeast, southeast, southwest, northwest);

Charges: individual medical expenses charged by health insurance.

Data Importation

```{r import}
# Importação do ficheiro csv
insurance = read.csv(file='insurance.csv', header= T, sep=';', dec ='.') 
```

After importing the selected file from the aforementioned database, we factorized the age and BMI variables.

For the age variable, the following age groups were defined:

- **Young adult:** Age between 17 and 30
- **Middle age:** Age between 31 and 45
- **Elderly:** Age 45 or older

For the BMI variable, the following divisions were made:

- **Underweight:** BMI is less than 18.5
- **Normal weight:** BMI is from 18.5 to 24.9
- **Overweight:** BMI is from 25 to 29.9
- **Obese:** BMI is 30 or more

```{r}
# Fatorização da variável idade em relação às taxas
jovem_adulto = (insurance$charges[0:444])
idade_media = (insurance$charges[445:838])
idade_avancada = (insurance$charges[839:1338])

values = c(jovem_adulto,idade_media,idade_avancada)
ind = c(rep('1',length(jovem_adulto)),
      rep('2',length(idade_media)),
      rep('3',length(idade_avancada)))

idade = factor(ind)

# Fatorização da variável bmi em relação às taxas

indice_massa = insurance[with(insurance, order(insurance$bmi, insurance$charges)), ]
baixo_peso = (indice_massa$charges[0:21])
peso_normal = (indice_massa$charges[22:245])
sobrepeso = (indice_massa$charges[246:631])
obeso = (indice_massa$charges[632:1338])

values2 = c(baixo_peso,peso_normal,sobrepeso,obeso)
ind2 = c(rep('1',length(baixo_peso)),
      rep('2',length(peso_normal)),
      rep('3',length(sobrepeso)),
      rep('4',length(obeso)))

bmi = factor(ind2)
```


```{r, echo = FALSE}
#ocultar do html
#fatorização da variável idade

jovem_adulto = (insurance$age[0:444])
idade_media = (insurance$age[445:838])
idade_avancada = (insurance$age[839:1338])

values3 = c(jovem_adulto,idade_media,idade_avancada)
ind3 = c(rep('1',length(jovem_adulto)),
        rep('2',length(idade_media)),
        rep('3',length(idade_avancada)))

idade2 = factor(ind3)

#fatorização da variável bmi
baixo_peso1= (indice_massa$bmi[0:21])
peso_normal1 = (indice_massa$bmi[22:245])
sobrepeso1 = (indice_massa$bmi[246:631])
obeso1 = (indice_massa$bmi[632:1338])

values4 = c(baixo_peso,peso_normal,sobrepeso,obeso)
ind4 = c(rep('1',length(baixo_peso1)),
      rep('2',length(peso_normal1)),
      rep('3',length(sobrepeso1)),
      rep('4',length(obeso1)))

bmi2 = factor(ind4)
```


## Informations
```{r}
# Informação preliminar do dataset
str(insurance)
```


```{r}
#Verificação da hipótese de existir dados em falta
any(is.na(insurance))
```

The dataset does not contain missing data (NA).

This dataset contains data from 1338 individuals, distributed across 7 variables as explained earlier, with 3 of them being continuous, one discrete (number of children), and 3 categorical. Among the categorical variables, two are binary (gender and smoker), and the other has 4 levels (region). The predictive variables include age, gender, BMI, number of children, smoker, and region.


## Exploratory Analysis
```{r}
#install.packages("summarytools")
library(summarytools)

dfSummary(insurance,na.col=F,valid.col=F)
```


The descriptive statistics are presented above.

### Age Variable
``` {r}
var(insurance$age)
sd(insurance$age)
boxplot (values3~idade2, names = c('jovem_adulto','idade_media','idade_avançada'), xlab = 'Faixas etárias', ylab = 'Idades', col = c('lightpink','lightgreen','lightblue'),main = 'Distribuição das idades por faixas etárias')
```

### Gender variable
``` {r}
genero = table(insurance$sex)
barplot (genero, ylim = c (0,700), names.arg = c('Feminino','Masculino'), col = c('lightpink','lightblue'), ylab = 'Número de pessoas', main = 'Número de pessoas por género' )
``` 

### BMI variable
``` {r}
var(insurance$bmi)
sd(insurance$bmi)
boxplot (values4~bmi2, names = c('baixo_peso','peso_normal','sobrepeso','obeso'), xlab = 'Faixas de BMI', ylab = 'Valores de BMI', col = c('lightpink','lightgreen','lightblue', 'lightyellow'),main = 'Distribuição das faixas de BMI por índice de massa corporal')
``` 

### Children variable
``` {r}
var(insurance$children)
sd(insurance$children)
boxplot(insurance$children, ylab = 'Número de filhos', main = 'Distribuição de filhos na população', col = 'lightblue')
color <- colorRampPalette(c("darkblue","lightblue"))
barplot(table (insurance$children), ylim = c(0,700), xlab = 'Número de filhos', ylab = 'Número de pessoas', main = 'Distribuição de filhos na população', col = color (6))
``` 

### Smokers variable
``` {r}
barplot (table(insurance$smoker), ylim = c(0,1200), names = c('Não fumador','Fumador'), main = 'Distribuição de fumadores na população',col =c('lightgreen','lightblue'), ylab = 'Número de pessoas')

``` 

### Region variable
``` {r}
regiao = table (insurance$region)
barplot (regiao, ylim = c(0,400), main = 'Distribuição das regiões',col =c('lightgreen','lightblue','lightpink','lightyellow'),ylab = 'Número de pessoas')
```

### Charges variable
``` {r}
var(insurance$charges)
sd(insurance$charges)
boxplot (insurance$charges, ylim= c(0,65000), main = 'Distribuição dos taxas médicos',ylab = 'Preço ($)',col = 'lightyellow')
```

## ANOVA Analysis

Since the dependent variable we aim to study is "charges", an analysis of this variable was conducted compared to the independent variables (gender, age, region, and BMI).


### Age Variable

``` {r}
# Boxplot da distribuição das taxas por faixas etárias
boxplot(values~idade,names = c('jovem_adulto','idade_media','idade_avançada'), xlab = 'Faixas etárias', ylab = 'Taxas', col = c('lightpink','lightgreen','lightblue'),main = 'Distribuição das taxas por faixas etárias')

#Procede-se à execução do fligner.test para comprovar a homogeneidade das variâncias.
fligner.test(insurance$charges~idade)
oneway.test(insurance$charges~idade,var.equal=F)
model= aov(insurance$charges~idade)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

Outliers were observed for all factors in the boxplot of charges by age groups. The factor with a relatively higher mean concerning charges is elderly age group. Regarding the ANOVA analysis, significant differences were observed between middle age and young adult, elderly and young adult, and between elderly and middle age.

### Gender variable
```{r}
boxplot(charges~sex, data=insurance, col = c('lightpink','lightgreen'), main = 'Distribuição das taxas por géneros', xlab = 'Género', ylab = 'Taxas', names = c('Feminino','Masculino'))

#Procede-se à execução do fligner.test para comprovar a homogeneidade das variâncias.
fligner.test(insurance$charges~insurance$sex)
oneway.test(insurance$charges~insurance$sex,var.equal=F)
model= aov(insurance$charges~insurance$sex)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

Through the boxplot of charges by gender, it is evident that both factors have outliers. The ANOVA analysis reveals significant differences between the levels (Female-Male) and the dependent variable.

### BMI variable
```{r}
# Boxplot da distribuição das taxas por Índice de massa corporal
boxplot(values2~bmi, names = c('baixo_peso', 'peso_normal', 'sobrepeso', 'obeso'), xlab = 'Índice de massa Corporal', ylab = 'Taxas', col = c('lightpink','lightgreen','lightblue', 'lightyellow'),main = 'Distribuição das taxas por índice de massa corporal')

#Procede-se à execução do fligner.test para comprovar a homogeneidade das variâncias.
fligner.test(indice_massa$charges~bmi)
oneway.test(indice_massa$charges~bmi,var.equal=F)
model= aov(indice_massa$charges~bmi)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

According to the analysis of the boxplot of charges by BMI, outliers are only present for "obesity", which also has the highest mean regarding charges. Through the ANOVA results analysis, significant differences are observed only between obesity and the other factors (underweight, normal weight, and overweight). Thus, the other factors do not show differences between them.


### Children variable
```{r}
boxplot(charges~children, data=insurance, col = color (6), main = 'Distribuição das taxas por número de filhos', xlab = 'Número de filhos', ylab = 'Taxas')

#Procede-se à execução do fligner.test para comprovar a homogeneidade das variâncias.
children = factor (insurance$children)
fligner.test(insurance$charges~children)
oneway.test(insurance$charges~children,var.equal=F)
model= aov(insurance$charges~children)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

According to the analysis of the boxplot of charges by the number of children variable, outliers are present. The factor 4 (number of children) has the highest mean regarding charges. Through the ANOVA results analysis, significant differences are observed between 0 and 2 children.


### Smoker variable
```{r}
boxplot(charges~smoker, data=insurance, col = c('lightpink','lightgreen'), main = 'Distribuição das taxas por fumadores', xlab = 'Fumadores', ylab = 'Taxas', names = c('Não','Sim'))


#Procede-se à execução do fligner.test para comprovar a homogeneidade das variâncias.
fligner.test(insurance$charges~insurance$smoker)
oneway.test(insurance$charges~insurance$smoker,var.equal = F)
oneway.test(insurance$charges~insurance$smoker,var.equal = T)
model= aov(insurance$charges~insurance$smoker)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

According to the analysis of the boxplot of charges by the smoker variable, outliers are only present for "no", which also has the lowest mean regarding charges. Through the ANOVA results analysis, significant differences are observed between the levels (No/Yes).

### Region variable
```{r}
boxplot(charges~region, data=insurance, col = c('lightpink','lightgreen', 'lightblue', 'lightyellow'), main = 'Distribuição das taxas por regiões', xlab = 'Região', ylab = 'Taxas')

#Procede-se à execução do fligner.test e shapiro.test para comprovar a homogeneidade das variâncias
fligner.test(insurance$charges~insurance$region)
oneway.test(insurance$charges~insurance$region,var.equal=F)
model= aov(insurance$charges~insurance$region)
summary(model)
TukeyHSD(model)
```

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis that declares the homogeneity of variances.

For an alpha of 0.05, since the p-value is less than alpha, we reject the null hypothesis, thus assuming that there are significant differences. Therefore, we proceed with Tukey's Honestly Significant Difference (TukeyHSD) test, which is a multiple comparison test.

Regarding the region variable, outliers are present in all factors. It is noteworthy that the factor with the highest mean regarding charges is "northeast". Considering the results from the ANOVA analysis, significant differences are observed only between southwest and southeast. Therefore, the other factors do not show differences between them.


## Correlations

Based on the Pearson correlation coefficient, the correlation between the quantitative variables was performed, which in this case are also continuous.

```{r}
# Criação de dataset com apenas variáveis numéricas
insurance_num <- insurance
insurance_num$sex<- NULL
insurance_num$region<- NULL
insurance_num$smoker<- NULL

# Correlações
#install.packages('ggplot2')
library (ggplot2)
library (GGally)

ggcorr(insurance_num, geom="tile", label= T, label_alpha=F, label_round=2)

```

Therefore, only correlations with values greater than 0.5 were considered relevant for the case study, assuming them as strong and positive correlations (1 is considered a perfect linear relationship).

Since none of the correlations obtained a value greater than 0.5, we can verify that none of the variables has a strong correlation with the insurance charges. However, "charges" has a weak positive correlation with "age", "bmi", and "children", with the highest correlation being between "charges" and "age" (0.3), which is logical and expected.

## Linear Regression (Full Model)


```{r}
full.model<- lm(charges~., data=insurance) 
summary(full.model)

#Teste a multicolinearidade   
car::vif(full.model)

```

Diagnostic measures:
The p-value and F-statistics have very low values, indicating that at least one predictor variable is related to the charges.

R^2^ -> 1, the value tends to 1, indicating that the predictor variables are well fitted in the model.

RSE -> 0, values below 0 produce lower model errors.

The value of RSE is 6062 and R^2^ is 75%. The intercept is -11938.5 and almost all predictor variables, except gender and the northwest region, are significant according to their p-values.
The interpretation of categorical variables, e.g., "smoker", can be interpreted as "average charges increase by 23848.5 if the individual is a smoker - with all other variables held constant".
The coefficient value, when significant, is the average change in charges with a one-unit increase in the predictor variable - with the others held constant.
While correlation measures the strength of the relationship, the coefficient quantifies the relationship and allows predictions from an equation.
For example, for each unit added to age, the expected average charge is 256.9 higher - after controlling for other variables.


```{r}
library (MASS)

step.model <- stepAIC(full.model, direction="both", trace=FALSE)
summary(step.model)
AIC(step.model)
```

```{r}
step.modelf <- stepAIC(full.model, direction='forward', trace=FALSE)
summary(step.modelf)
AIC(step.modelf)
```

### Plots
The Residuals vs Fitted plot linearly relates the residuals and the predictor variable.

The Normal Q-Q plot visually assesses whether the residuals follow a normal distribution. Later, a Shapiro test was performed to verify normality.

The Scale-Location plot checks the homogeneity of residuals and the constant variance regression criterion.

The Residuals vs Leverage plot identifies the values that most influence the regression.

```{r}
step.modelb <- stepAIC(full.model, direction='backward', trace=FALSE)
summary(step.modelb)
AIC(step.modelb)
plot(step.modelb)

```

No gráfico Residuals vs Fitted, the non-horizontal red line may indicate a non-linear relationship.

In the Normal Q-Q plot, we see that the residuals are not exactly on the straight line, indicating that they are not normally distributed.

In the Scale-Location plot, the non-straight line indicates heteroscedasticity (different variances for all observations).

The contradictory assumptions obtained indicate that this model does not allow for reliable conclusions.

Finally, the stepwise selection method was performed from the full model fit. For this, the 'backward', 'forward', and 'both' direction methods were used. Then, a comparison of the AIC values for the three aforementioned methods was conducted, and the 'backward' method was chosen because it has the lowest AIC value.


```{r}
anova(full.model)     

anova(step.modelf)

anova(step.modelb)
```


```{r}
# Distância de cook para visualizar se há pontos influentes na regressão do step.modelb 
n=1338
cook = cooks.distance(step.modelb)
pontInf = which(cook>4/n) # Para ver os pontos com distância de cook superior a uma unidade
pontInf

summary(cook)
```

A Cook's distance is one method used to identify influential points in regression analysis. If the values of the distances are greater than 4/n, where n is the sample size, it indicates that these values exist and should be considered.

The Cook's distance was used to check for the existence of points that may influence the regression. To determine if the distance is large enough to consider influential values, it must have a value greater than 4/n, which in this case is 0.003. Although on average the values of the distances are less than 0.003, we can see, for example, that the maximum value is much higher than the reference value, proving that there is at least one value influencing the results.   

```{r}
n= 1338
cook2 = cooks.distance(step.modelf)
pontInf = which(cook2>4/n) # Para ver os pontos com distância de cook superior a 1 unidade

summary(cook2)
```

```{r}
#leverage : hj>2(p+1)/n para que na observação possam ser considerados outliers
n = 1338
p = 7
  
limhj = (2*(p+1))/n
limhj
```

As we obtained a value greater than 0, it means that outliers are being considered for the regressions. Given that we observe the existence of outliers, these may be influencing other results such as correlation.

```{r}
# Consideração de outliers no comportamento do step.modelb
hj = hatvalues(step.modelb)
out = which(hj>limhj)
out
summary(hj)
```

From these results, we can see which outliers are influencing the regression in the step.modelb.

```{r}
# Consideração de outliers no comportamento do step.modelf
hj2=hatvalues(step.modelf)
out=which(hj2>limhj)
out

summary(hj2)
```

From these results, we can see which outliers are influencing the regression in the step.modelf.

## Conclusions
### Residuals Conditions Verification
```{r}
shapiro.test(residuals(step.modelb))
#shapiro.test(residuals(cook))
t.test(residuals(step.modelb))
sigma(step.modelb)/mean(insurance$charges)
plot(step.modelb)

plot(step.modelb$fitted.values, step.modelb$residuals,ylab="resíduos",xlab="previstos")
abline(h=0,lty=2,col=2)

```

Based on the alpha value being 0.05, since the p-value < alpha, we reject the null hypothesis that declares the normality of residuals.
With a p-value = 1, we can conclude that the mean is 0, which aligns with one of the assumptions of ANOVA.

```{r}
boxplot(step.modelb$residuals,col= 'lightgreen', ylim = c(-15000,35000))

boxplot.stats(step.modelb$residuals)
```

In conclusion, we can observe that:

Regarding exploratory analysis, the mean and median in the age variable present very similar values, and ages are distributed similarly without outliers detected. The youngest patient is 18 years old, and the oldest is 64.

There are slightly more men than women, with this difference being around 1%.

In BMI, there is an asymmetric distribution of results as patients fit into different categories. The mean and median have very close values, almost identical. Some outliers can be detected in all groups, with a greater presence in the obese group, as expected since this group has the most samples. The minimum BMI in the sample is 16, and the maximum is 53.1.

In the case of children, the mean and median have very close values, but the distribution of values is highly disproportional, with about 43% having no children. Among patients who have children, most (24%) have 1 child, with the maximum in this sample being 5 children (1%).

There is a significant difference between smoking and non-smoking patients regarding their distribution (20% and 80%, respectively).

Regarding the regions variable, the values are distributed similarly except for the South East group, which has a slightly higher value (27%).

For the charges variable, we can see that the mean and median are very different from each other, showing a high skewness in the sample. From the boxplot, several outliers can be detected. The minimum value is 1121.9, and the maximum is 63770.4.

Through the ANOVA test, it was possible to see if there were significant differences in prices within each of the variables. It was demonstrated that, for example, being a smoker or being older causes an increase in the insurance value since they are presumably people who need greater medical attention due to a weaker health condition. The results obtained in this test were in line with those of the t-test performed at the end.

We also observed that when correlating quantitative variables with the charges variable, there were not very significant results except for one, which, although weak, was relatively close to 0.5 (threshold used to consider a strong correlation), which was age. This was an expected result because, as mentioned before, older people need much more medical attention than younger patients.

Finally, by examining the graphs obtained from the linear regression analysis and the Shapiro test, we saw that we did not obtain normality in our results. This was confirmed by checking the Cook's distance and observing the information from the residuals boxplot, which showed the presence of several values that are significantly influencing the results. These outliers may have a significant impact, affecting the correlations previously analyzed considerably.

In addition to the outliers that are causing changes in the final results, some variables such as smoker and children present highly skewed distributions of values, which also influence the impact of these during the analysis.

We were able to verify that smoking is a significant indicator for the increase in insurance prices, caused by the need for greater medical attention, and we also observed that insurance prices do not increase gradually with the number of children. From the boxplot made of prices based on the number of children, we see that having 3 children covered by insurance seemed to be cheaper than having only 2 children, and having 5 children seems to lead to a smaller price increase than having 4. This can be explained by the unequal number of values being analyzed for each group, as we have, for example, 18 patients with 5 children and 324 with only 1.
